#-*- coding:utf-8 -*-
import os
import sys
import cv2
import json
import numpy as np
import torch
import pandas as pd
from torch.autograd import Variable
import torch.nn.functional as F
import torch.utils.data
from torch import nn
from opts import parse_opts
from model import generate_model
from sklearn.cluster import DBSCAN
import time
opt = parse_opts()
def soft_l1(img, a, b, w):
    img_o = img.copy()
    img_o = np.float32(img_o)
    if np.sum(img_o > b):
        x = img_o[img_o > b]
        img_o[img_o > b] = b + w / (1 + np.exp((b - x) / w)) - w / 2
    if np.sum(img_o < a):
        x = img_o[img_o < a]
        img_o[img_o < a] = a + w / (1 + np.exp((a - x) / w)) - w / 2
    img_o = img_o - (a - w / 2)
    img_o = img_o / (b - a + w) * 255
    return img_o.astype(np.uint8)

def get_data(image_name, mask_name, sample_size):
    image = np.load(image_name)
    mask = np.load(mask_name)

    if np.max(mask)>1:
        mask = mask / np.max(mask)
    
    height,width,depth = image.shape
    if height!=sample_size:
        image = cv2.resize(image, (sample_size,sample_size,depth))
        mask = cv2.resize(mask, (sample_size,sample_size,depth))
    image = soft_l1(image,-1350,150,150.0)
    image = np.expand_dims(image,0).transpose(3,0,1,2)
    mask = mask.transpose(2,0,1)
    return image, mask

def get_seg_outputs(preds, mask, name, seg_pred_thresh):
    '''
    method: get segment result for classify
    preds: batch*height*width
    seg_outs: csv file, x,y,z,d_x,d_y, prob.最终的分割预测结果,用于分类
    '''
    seg_results=pd.DataFrame()
    #获得candidate 分割位置
    if type(preds) is not np.ndarray:
        preds = np.array(preds)
    beg_time = time.time()
    #preds = preds*mask
    num=0
    for i, pred in enumerate(preds):
        _, contours, _ = cv2.findContours(255 * np.uint8(pred >= seg_pred_thresh), cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        for j,cnt in enumerate(contours):
            # 计算轮廓的半径
            w_min, h_min, w, h = cv2.boundingRect(contours[j]) 
            w_max, h_max = w_min+w, h_min+h
            prob = np.max(pred[h_min:h_max + 1, w_min:w_max + 1])
     
            x = np.int(np.ceil((w_max + w_min) / 2))
            y = np.int(np.ceil((h_max + h_min) / 2))
            z= i
            d = np.int(np.max([w, h]))

            if mask[z, y, x] == 0:
                pass
            else:
                seg_results.loc[num,'x']=x
                seg_results.loc[num,'y']=y
                seg_results.loc[num,'z']=z
                seg_results.loc[num,'dx']=w
                seg_results.loc[num,'dy']=h
                seg_results.loc[num,'prob']=prob
                num+=1
    print(time.time()-beg_time)

    #聚类获得最终分割结果
    seg_outs = pd.DataFrame(columns=seg_results.columns)
    #seg_results['cluster']= 0 
    data = seg_results[['x','y','z']]
    dbscan = DBSCAN(eps=6, min_samples=1)
    seg_results['cluster'] = dbscan.fit_predict(data)
    for k in seg_results.cluster.unique():
        voxel = seg_results.loc[seg_results.cluster==k,['x','y','z','dx','dy','prob']].values.mean(axis=0)
        seg_outs.loc[k,'x']=voxel[0]
        seg_outs.loc[k,'y']=voxel[1]
        seg_outs.loc[k,'z']=voxel[2]
        seg_outs.loc[k,'dx']=voxel[3]
        seg_outs.loc[k,'dy']=voxel[4]
        seg_outs.loc[k,'prob']=voxel[5]
    seg_outs['ID']=name[:-4]
    return seg_outs


def predict_demo(image_path, mask_path, seg_pred_thresh=0.7):
    print('loading model')
    model, parameters = generate_model(opt) 
    resume_file = '/media/wowjoy/7E24709324704FDF/PycharmProjects/Lung_Nodules_Detection/Code/2D-deeplab-3D-resnet/demo/trained_models/seg_save_159.pth'
    print('loading checkpoint {}'.format(resume_file))    
    checkpoint = torch.load(resume_file)   
    opt.begin_epoch = checkpoint['epoch']
    state_dict = checkpoint['state_dict']  

    if not opt.no_cuda:   #使用GPU
        model.load_state_dict(state_dict)
    else:                 #使用CPU:
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            name = k[7:] # remove `module.`
            new_state_dict[name] = v
        model.load_state_dict(new_state_dict)


    #creat predict dataset
    seg_outs=pd.DataFrame()
    names = os.listdir(image_path)
    for name in names:
        print('creat predict data:',name)
        image_name = os.path.join(image_path,name)
        mask_name = os.path.join(mask_path,name) 
        if not os.path.exists(image_name):
            continue
        if not os.path.exists(mask_name):
            continue
        image, mask = get_data(image_name, mask_name, 512)
        image_tensor = torch.from_numpy(image)
        predict_data = torch.utils.data.TensorDataset(image_tensor) 
        predict_loader = torch.utils.data.DataLoader(predict_data,batch_size=opt.val_batch_size,shuffle=False,num_workers=opt.n_threads,pin_memory=True)

        print('patient predict:',name)
        model.eval()
        preds = []
        for i, (inputs,) in enumerate(predict_loader):
            import pdb
            #pdb.set_trace()
            inputs = Variable(inputs,  requires_grad=False).type(torch.float32)
            output = model(inputs)
            '''
            if not opt.no_softmax_in_test:
                output = F.softmax(output)
            pred = output.max(1)[1].data.cpu().numpy()
            '''
            output = F.softmax(output)
            pred = output.data.cpu().numpy()[:,1,:,:]
            preds.extend(pred)
        pdb.set_trace()
        patient_out = get_seg_outputs(preds, mask, name, seg_pred_thresh)
        seg_outs.append(patient_out)
    seg_outs.to_csv('predice_results.csv',axis=False)
    return 

if __name__ == '__main__':
    image_path = '../../origin_datas/image'
    mask_path = '../../origin_datas/mask'
    predict_demo(image_path, mask_path)
    







