# -*- encoding: utf-8 -*-
'''
@time: 2018  下午3:45

@author: wowjoy
'''

import os
import numpy as np
import pandas as pd
import multiprocessing
from multiprocessing.dummy import Pool as ThreadPool
import pdb

main_ip = os.path.join(os.getcwd(),'../../origin_datas/')
data_ip = os.path.join(main_ip,'image')
csv_ip = os.path.join(main_ip,'csv')

main_op = os.path.join(os.getcwd(), '../data/classify')
pos_data_op = os.path.join(main_op,'image_pos')
neg_data_op = os.path.join(main_op,'image_neg')

if not os.path.exists(pos_data_op):
    os.makedirs(pos_data_op)
if not os.path.exists(neg_data_op):
    os.makedirs(neg_data_op)

def padd_zeros(data,size=32):
    image = np.zeros(shape=[size,size,size])
    height,width,depth = data.shape
    image[:height,:width,:depth]=data
    return image

def soft_l1(img, a, b, w):
    img_o = img.copy()
    img_o = np.float32(img_o)
    if np.sum(img_o > b):
        x = img_o[img_o > b]
        img_o[img_o > b] = b + w / (1 + np.exp((b - x) / w)) - w / 2
    if np.sum(img_o < a):
        x = img_o[img_o < a]
        img_o[img_o < a] = a + w / (1 + np.exp((a - x) / w)) - w / 2
    img_o = img_o - (a - w / 2)
    img_o = img_o / (b - a + w) * 255
    return img_o.astype(np.uint8)

def create_singledata(data, x, y, z, size=32):
    r = size / 2
    if data[y - r:y + r, x - r:x + r, z - r:z + r].shape == (size, size, size):
        nodule = data[y - r:y + r, x - r:x + r, z - r:z + r]
    else:
        nodule = padd_zeros(data[y - r:y + r, x - r:x + r, z - r:z + r],size)
    nodule = soft_l1(nodule, -1350, 150, 150.0)
    return nodule

def get_pos_sample(pos_job):
    old_name,pos_num,x,y,z,size =pos_job
    print('get classify annotations, loop:', pos_num)
    data = np.load(os.path.join(data_ip, old_name))
    nodule = create_singledata(data, x, y, z, size)
    table = []
    # 数据增强：翻转
    table.append(nodule)
    table.append(nodule[::-1])
    table.append(nodule[:, ::-1])
    table.append(nodule[:, :, ::-1])
    table.append(nodule[::-1, ::-1])
    table.append(nodule[:, ::-1, ::-1])
    table.append(nodule[::-1, :, ::-1])
    table.append(nodule[::-1, ::-1, ::-1])
    for k, data in enumerate(table):
        new_name = '%06d.npy'%(8*pos_num+k+1)
        np.save(os.path.join(pos_data_op, new_name), data)

def get_classify_pos_set(pos_info):
    pool = ThreadPool(8)
    size =32
    pos_jobs = []    
    c_x = pos_info['voxelX'].values
    c_y = pos_info['voxelY'].values
    c_z = pos_info['voxelZ'].values
    c_id = pos_info['ID'].values
    for j in range(c_id.shape[0]):#
        old_name = c_id[j]+'.npy'
        pos_jobs.append((old_name,j,int(c_x[j]),int(c_y[j]),int(c_z[j]),size))
    pool.map(get_pos_sample,pos_jobs)
    pool.close() 
    pool.join()


def get_neg_sample(neg_job):
    old_name, neg_num, x, y, z, size =neg_job
    print('get classify annotations, loop:', neg_num)
    new_name = '%06d.npy' % neg_num
    data = np.load(os.path.join(data_ip, old_name))
    nodule = create_singledata(data, x, y, z, size)
    np.save(os.path.join(neg_data_op, new_name), nodule)

def get_classify_neg_set(neg_info,size):
    pool = ThreadPool(8)
    neg_jobs = []
    neg_num = 0
    c_x = neg_info['voxelX'].values
    c_y = neg_info['voxelY'].values
    c_z = neg_info['voxelZ'].values
    c_id = neg_info['ID'].values
    for j in range(c_id.shape[0]):#
        old_name = c_id[j]+'.npy'
            neg_num = j+1
        if neg_num<302480:
            neg_jobs.append((old_name,neg_num,int(c_x[j]),int(c_y[j]),int(c_z[j]),size))
    pool.map(get_neg_sample,neg_jobs)
    pool.close() 
    pool.join() 


def get_classify_set():
    size =32
    csv_file = os.path.join(csv_ip, 'candidates_detail_all.csv')
    c_info = pd.read_csv(csv_file,dtype={'ID':str})
    pos_info = c_info[c_info['class']==1].values
    neg_info = c_info[c_info['class']==0].values
    get_classify_pos_set(pos_info,size)
    get_classify_neg_set(neg_info,size)
if __name__ == '__main__':
    get_classify_set()
















